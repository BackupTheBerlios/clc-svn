.\" Updated 10/5/1998 by Nicolás Lichtmaier <nick@debian.org>
.de FN
\fI\|\\$1\|\fP
..
.TH WGET 1 "May 1998" "Debian GNU/Linux"
.SH NAME
wget \- a utility to retrieve files from the World Wide Web
.SH SYNOPSIS
.B wget
.I [options] [URL-list]
.SH WARNING
The information in this man page is an extract from the full
documentation of
.BR Wget .
It may contain inaccuracies.  Please refer to the info page for full,
up\-to\-date documentation.  You can view the info documentation with
the \fBemacs\fP(1) info subsystem or the standalone \fBinfo\fP(1) program.
.SH DESCRIPTION
.B Wget
is a utility designed for retrieving binary documents across the Web,
through the use of \fIHTTP\fP (Hyper Text Transfer Protocol) and
\fIFTP\fP (File Transfer Protocol), and saving them to disk.
.B Wget
is non\-interactive, which means it can work in the background, while
the user is not logged in, unlike most of web browsers (thus you may
start the program and log off, letting it do its work). Analyzing
server responses, it distinguishes between correctly and incorrectly
retrieved documents, and retries retrieving them as many times as
necessary, or until a user\-specified limit is reached. \fIREST\fP is
used in \fIFTP\fP on hosts that support it. Proxy servers are
supported to speed up the retrieval and lighten network load.
.PP
.B Wget
supports a full-featured recursion mechanism, through which you can
retrieve large parts of the web, creating local copies of remote
directory hierarchies. Of course, maximum level of recursion and other
parameters can be specified. Infinite recursion loops are always
avoided by hashing the retrieved data. All of this works for both
\fIHTTP\fP and \fIFTP\fP.
.PP
The retrieval is conveniently traced with printing dots, each dot
representing one kilobyte of data received. Builtin features offer
mechanisms to tune which links you wish to follow (cf. \fB-L\fP, \fB-D\fP and \fB-H\fP).

.SH "URL CONVENTIONS"
.PP
Most of the URL conventions described in RFC1738 are supported. 

Normal URL (recommended form):
.nf
http://host[:port]/path
ftp://host[:port]/path
.fi
You may encode your username and/or password to URL using the form:

.nf
ftp://user:password@host/path
http://user:password@host/path

.fi

.B Wget
also supports the `type' feature for FTP URLs.  By default, FTP
documents are retrieved in the binary mode (type `i'), which means that
they are downloaded unchanged.  Another useful mode is the `a'
("ASCII") mode, which converts the line delimiters between the
different operating systems, and is thus useful for text files.  Here
is an example:
.nf
ftp://host/dir/file;type=a
.fi

Two alternative syntaxes are also supported, because of historical
(hysterical?) reasons and their wide-spreadedness.

\fIFTP\fP only (ncftp-like):
hostname:/dir/file

.nf
\fIHTTP\fP only (netscape-like):
hostname(:port)/dir/file

.fi
   These two alternative forms are deprecated, and may cease being
supported in the future.

   If you do not understand the difference between these notations, or
do not know which one to use, just use the plain ordinary format you use
with your favorite browser, like 
.BR lynx "(1) or " netscape (1).

.SH OPTIONS
.PP
There are quite a few command\-line options for
.BR wget .
Note that you do not have to know or to use them unless you wish to
change the default behaviour of the program. For simple operations you
need no options at all. It is also a good idea to put frequently used
command\-line options in \fI.wgetrc\fP, where they can be stored in a more
readable form.
.PP
This is the complete list of options with descriptions, sorted in
descending order of importance:
.TP
.B "-h --help"
Print a help screen. You will also get help if you do not supply
command\-line arguments.
.TP
.B "-V --version"
Display version of
.BR wget .
.TP
.B "-v --verbose"
Verbose output, with all the available data. The default output
is verbose.
.TP
.B "-q --quiet"
Quiet mode, with no output at all.
.TP
.B "-d --debug"
Debug output, and will work only if
.B wget
was compiled with -DDEBUG. Note that when the program is compiled with
debug output, it is not printed unless you specify -d.
.TP
.BI "--dot-style=" STYLE
Set the retrieval style to \fISTYLE\fP.  \fBWget\fP traces the retrieval of
each document by printing dots on the screen, each dot
representing a fixed amount of retrieved data.  Any number of dots
may be separated in a "cluster", to make counting easier.  This
option allows you to choose one of the pre-defined styles,
determining the number of bytes represented by a dot, the number
of dots in a cluster, and the number of dots on the line.

With the `default' style each dot represents 1K, there are ten dots
in a cluster and 50 dots in a line.  The `binary' style has a more
"computer"-like orientation--8K dots, 16-dots clusters and 48 dots
per line (which makes for 384K lines).  The `mega' style is
suitable for downloading very large files--each dot represents 64K
retrieved, there are eight dots in a cluster, and 48 dots on each
line (so each line contains 3M).  The `micro' style is exactly the
reverse; it is suitable for downloading small files, with 128-byte
dots, 8 dots per cluster, and 48 dots (6K) per line.
.TP
.B "-b --background"
Go to background immediately after startup.
.TP
.B "-i \fIfilename\fP --input-file=\fIfilename\fP"
Read URL-s from
.I filename,
in which case no URL\-s need to be on the command line. If there are
URL\-s both on the command line and in a filename, those on the
command line are first to be retrieved. The filename need not be an
\fIHTML\fP document (but no harm if it is) - it is enough if the URL-s
are just listed sequentially.

However, if you specify \fB--force-html\fP, the document will be regarded as
\fIHTML\fP. In that case you may have problems with relative links,
which you can solve either by adding <base href="url"> to the document
or by specifying \fB--base=url\fP on the command\-line.
.TP
.B "-o \fIlogfile\fP --output-file=\fIlogfile\fP"
Log messages to \fIlogfile\fP. The messages are normally sent to
standard error.
.TP
.B "-a \fIlogfile\fP --append-output=\fIlogfile\fP"
Append to logfile - same as \fB-o\fP, but appends to a logfile (or creating
a new one if the old does not exist) instead of rewriting the old log
file.
.TP
.B "-t \fInum\fP --tries=\fInum\fP"
Set number of retries to
.I num.
Specify 0 or `inf' for infinite retrying.
.TP
.B "--follow-ftp"
Follow \fIFTP\fP links from \fIHTML\fP documents.
.TP
.B "-c --continue-ftp"
Continue retrieval of FTP documents, from where it was left off. If
you specify "wget -c ftp://sunsite.doc.ic.ac.uk/ls-lR.Z", and there
is already a file named ls-lR.Z in the current directory,
.B wget
continue retrieval from the offset equal to the length of the existing
file. Note that you do not need to specify this option if the only
thing you want is
.B wget
to continue retrieving where it left off when the connection is lost -
.B wget
does this by default. You need this option when you want to continue
retrieval of a file already halfway retrieved, saved by other FTP
software, or left by
.B wget
being killed. The \fB-c\fP option is also applicable for HTTP servers that
support the `Range' header.
.TP
.B --retr-symlinks
Retrieve symbolic links on FTP sites as if they were plain files,
i.e. don't just create links locally.
.TP
.B "-g \fIon/off\fP --glob=\fIon/off\fP"
Turn FTP globbing on or off. By default, globbing will be turned on if
the URL contains a globbing characters (an asterisk, e.g.). Globbing
means you may use the special characters (wildcards) to retrieve more
files from the same directory at once, like wget
ftp://gnjilux.cc.fer.hr/*.msg. Globbing currently works only on UNIX FTP
servers (and the ones emulating Unix `ls' output).
.TP
.B --passive-ftp
Use the "passive" FTP retrieval scheme, in which the client
initiates the data connection.  This is sometimes required for FTP
to work behind firewalls.
.TP
.B "-e \fIcommand\fP --execute=\fIcommand\fP"
Execute \fIcommand\fP, as if it were a part of \fI.wgetrc\fP file. A
command invoked this way will take precedence over the same command
in \fI.wgetrc\fP, if there is one.
.TP
.B "-N --timestamping"
Use the so\-called time\-stamps to determine whether to retrieve a
file. If the last\-modification date of the remote file is equal to,
or older than that of local file, and the sizes of files are equal,
the remote file will not be retrieved. This option is useful for
weekly mirroring of
.I HTTP
or
.I FTP
sites, since it will not permit downloading of the same file twice.
.TP
.B "-F --force-html"
When input is read from a file, force it to be \fIHTML\fP. This
enables you to retrieve relative links from existing \fIHTML\fP files
on your local disk, by adding <base href="URL"> to \fIHTML\fP, or using
.BR \-\-base .
.TP
.B "-B \fIbase_href\fP --base=\fIbase_href\fP"
Use \fIbase_href\fP as base reference, as if it were in the file, in
the form <base href="base_href">. Note that the base in the file will
take precedence over the one on the command\-line.
.TP
.B "-r --recursive"
Recursive web\-suck. According to the protocol of the URL, this can
mean two things. Recursive retrieval of a \fIHTTP\fP URL means that
.B Wget
will download the URL you want, parse it as an \fIHTML\fP document (if
an \fIHTML\fP document it is), and retrieve the files this document is
referring to, down to a certain depth (default 5; change it with \fB-l\fP).
.B Wget
will create a hierarchy of directories locally, corresponding to the
one found on the \fIHTTP\fP server.

This option is ideal for presentations, where slow connections should
be bypassed. The results will be especially good if relative links
were used, since the pages will then work on the new location without
change.

When using this option with an \fIFTP\fP URL, it will retrieve all the
data from the given directory and subdirectories, similar to
\fIHTTP\fP recursive retrieval.

You should be warned that invoking this option may cause grave
overloading of your connection. The load can be minimized by lowering
the maximal recursion level (see -l) and/or by lowering the number of
retries (see \fB-t\fP).
.TP
.B --spider
When invoked with this option, \fBWget\fP will behave as a Web "spider",
which means that it will not download the pages, just check that
they are there.  You can use it to check your bookmarks, e.g. with:

wget --spider --force-html -i bookmarks.html

This feature needs much more work for \fBWget\fP to get close to the
functionality of real WWW spiders.
.TP
.B "-m --mirror"
Turn on options suitable for mirroring.  This option turns on
recursion and time-stamping, sets infinite recursion depth and
keeps FTP directory listings.  It is currently equivalent to
.BR "-r -N -l inf -nr" .
.TP
.B -nr --dont-remove-listing
Don't remove the temporary \fI.listing\fP files generated by FTP
retrievals.  Normally, these files contain the raw directory
listings received from FTP servers.  Not removing them can be
useful to access the full remote file list when running a mirror,
or for debugging purposes.
.TP
.B "-l \fIdepth\fP --level=\fIdepth\fP"
Set recursion depth level to the specified level. Default is 5.
After the given recursion level is reached, the sucking will proceed
from the parent. Thus specifying \fB-r -l1\fP should equal a recursion\-less
retrieve from file. Setting the level to zero makes recursion depth
(theoretically) unlimited. Note that the number of retrieved documents
will increase exponentially with the depth level.
.TP
.B "-H --span-hosts"
Enable spanning across hosts when doing recursive retrieving. See
\fB-r\fP and \fB-D\fP. Refer to
.I FOLLOWING LINKS
for a more detailed description.
.TP
.B "-L --relative"
Follow only relative links. Useful for retrieving a specific homepage
without any distractions, not even those from the same host. Refer to
.I FOLLOWING LINKS
for a more detailed description.
.TP
.B "-D \fIdomain\-list\fP --domains=\fIdomain\-list\fP"
Set domains to be accepted and DNS looked-up, where domain\-list is a
comma\-separated list. Note that it does not turn on \fB-H\fP. This speeds
things up, even if only one host is spanned. Refer to
.I FOLLOWING LINKS
for a more detailed description.
.TP
.BI --exclude-domains\  DOMAIN-LIST
Exclude the domains given in a comma-separated \fIDOMAIN-LIST\fP from
DNS-lookup.
.TP
.B "-A \fIacclist\fP / -R \fIrejlist\fP --accept=\fIacclist\fP / --reject=\fIrejlist\fP"
Comma\-separated list of extensions to accept/reject. For example, if
you wish to download only GIFs and JPEGs, you will use -A gif,jpg,jpeg.
If you wish to download everything except cumbersome MPEGs and .au
files, you will use -R mpg,mpeg,au.
.TP
.B "-X \fIlist\fP --exclude-directories=\fIlist\fP"
Comma\-separated list of directories to exclude from FTP fetching.
.TP
.B "-P \fIprefix\fP --directory-prefix=\fIprefix\fP"
Set directory prefix ("." by default) to
\fIprefix\fP. The directory prefix is the directory where all other
files and subdirectories will be saved to.
.TP
.B "-T \fIvalue\fP --timeout=\fIvalue\fP"
Set the read timeout to a specified value. Whenever a read is issued,
the file descriptor is checked for a possible timeout, which could
otherwise leave a pending connection (uninterrupted read). The default
timeout is 900 seconds (fifteen minutes). Setting timeout to 0 will
disable checking for timeouts.

Please do not lower the default timeout value with this option
unless you know what you are doing.
.TP
.BI -w " SECONDS " --wait= SECONDS
Wait the specified number of seconds between the retrievals.  Use
of this option is recommended, as it lightens the server load by
making the requests less frequent.  Instead of in seconds, the
time can be specified in minutes using the `m' suffix, in hours
using `h' suffix, or in days using `d' suffix.

Specifying a large value for this option is useful if the network
or the destination host is down, so that \fBWget\fP can wait long enough
to reasonably expect the network error to be fixed before the
retry.
.TP
.B "-Y \fIon/off\fP --proxy=\fIon/off\fP"
Turn proxy on or off. The proxy is on by default if the appropriate
environmental variable is defined.
.TP
.B "-Q \fIquota[KM]\fP --quota=\fIquota[KM]\fP"
Specify download quota, in bytes (default), kilobytes or
megabytes. More useful for rc file. See below.
.TP
.BI "-O " filename " --output-document=" filename
The documents will not be written to the appropriate files, but all
will be appended to a unique file name specified by this option. The
number of tries will be automatically set to 1. If this filename is
`-', the documents will be written to stdout, and --quiet will be
turned on. Use this option with caution, since it turns off all the
diagnostics
.B Wget
can otherwise give about various errors.
.TP
.B "-S --server-response"
Print the headers sent by the \fIHTTP\fP server and/or responses sent
by the \fIFTP\fP server.
.TP
.B "-s --save-headers"
Save the headers sent by the \fIHTTP\fP server to the file, before the
actual contents.
.TP
.BI --header= additional-header
Define an ADDITIONAL-HEADER to be passed to the HTTP servers.
Headers must contain a `:' preceded by one or more non-blank
characters, and must not contain newlines.
You may define more than one additional header by specifying
\fB--header\fP more than once.
.TP
.B "--http-user=\fIUSER\fP --http-passwd=\fIPASSWORD\fP"
Specify the username \fIUSER\fP and password \fIPASSWORD\fP on an HTTP server.
According to the type of the challenge,
.B Wget
will encode them
using either the `basic' (insecure) or the `digest' authentication
scheme.
.TP
.B -nc
Do not clobber existing files when saving to directory hierarchy
within recursive retrieval of several files. This option is
.B extremely
useful when you wish to continue where you left off with retrieval.
If the files are .html or (yuck) .htm, it will be loaded from
the disk, and parsed as if they have been retrieved from the Web.
.TP
.B -nv
Non\-verbose \- turn off verbose without being completely quiet (use
-q for that), which means that error messages and basic information
still get printed.
.TP
.B -nd --no-directories
Do not create a hierarchy of directories when retrieving
recursively. With this option turned on, all files will get
saved to the current directory, without clobbering (if
a name shows up more than once, the filenames will get
extensions .n).
.TP
.B -x --force-directories
The opposite of \-nd. Force creation of a hierarchy of directories
even if it would not have been done otherwise.
.TP
.B -nh --no-host-lookup
Disable time-consuming DNS lookup of almost all hosts. Refer to
.I FOLLOWING LINKS
for a more detailed description.
.TP
.B -nH --no-host-directories
Disable host-prefixed directories. By default, http://fly.cc.fer.hr/
will produce a directory named fly.cc.fer.hr in which everything else
will go. This option disables such behaviour.
.TP
.BI --cut-dirs= NUMBER
Removes NUMBER components from the resulting output directories used with
-r. Does not remove the first level, the name of the remote host, use -nH to
remove that.
.TP
.B --no-parent
Do not ascend to parent directory. This is a useful option, since it
guarantees that only the files *below* a certain hierarchy will be
downloaded.
.TP
.B "-k --convert-links"
Convert the non-relative links to relative ones locally.  Only the
references to the documents actually downloaded will be converted;
the rest will be left unchanged.

Note that only at the end of the download can \fBWget\fP know which
links have been downloaded.  Because of that, much of the work
done by \fB-k\fP will be performed at the end of the downloads.

.SH "FOLLOWING LINKS"
Recursive retrieving has a mechanism that allows you to specify which
links
.B wget
will follow.
.TP
.B "Only relative links"
When only relative links are followed (option \fB-L\fP), recursive
retrieving will never span hosts.
.br gethostbyname (3)
will never get called, and the process will be very fast, with the
minimum strain of the network. This will suit your needs most of the
time, especially when mirroring the output the output of *2html
converters, which generally produce only relative links.
.TP
.B "Host checking"
The drawback of following the relative links solely is that humans
often tend to mix them with absolute links to the very same host,
and the very same page. In this mode (which is the default), all
URL-s that refer to the same host will be retrieved.

The problem with this options are the aliases of the hosts and domains.
Thus there is no way for
.B wget
to know that \fBregoc.srce.hr\fP and \fBwww.srce.hr\fP are the same
hosts, or that \fBfly.cc.fer.hr\fP is the same as \fBfly.cc.etf.hr\fP.
Whenever an absolute link is encountered, \fBgethostbyname\fP is
called to check whether we are really on the same host.  Although
results of \fBgethostbyname\fP are hashed, so that it will never get
called twice for the same host, it still presents a nuisance e.g. in
the large indexes of difference hosts, when each of them has to be
looked up. You can use -nh to prevent such complex checking, and then
.B wget
will just compare the hostname. Things will run much faster, but
also much less reliable.

Note that HTTP/1.1 allows one IP address to support several virtual
servers, each of them with its own root; this feature is also used by
many HTTP/1.0 servers.  Such "servers" are then distinguished by their
hostnames (all of which point to the same IP address); for this to
work, a client must send a `Host' header, which is what Wget does.
However, in that case Wget *must not* try to divine a host's "real"
address, nor try to use the same hostname for each access, i.e. \fB-nh\fP
must be turned on.

In other words, the \fB-nh\fP option must be used to enabling the
retrieval from virtual servers distinguished by their hostnames.  As the
number of such server setups grow, the behavior of \fB-nh\fP may become the
default in the future.
.TP
.B "Domain acceptance"
With the -D option you may specify domains that will be followed.
The nice thing about this option is that hosts that are not from
those domains will not get DNS-looked up. Thus you may specify
-D\fImit.edu\fP,
.B "just to make sure that nothing outside .mit.edu gets looked up".
This is very important and useful. It also means that -D does
\fBnot\fP imply -H (it must be explicitly specified). Feel free to use
this option, since it will speed things up greatly, with almost all
the reliability of host checking of all hosts.

Of course, domain acceptance can be used to limit the retrieval to
particular domains, but freely spanning hosts within the domain,
but then you must explicitly specify \fB-H\fP.

If there are domains you want to exclude specifically, you can do it
with \fB--exclude-domains\fP, which accepts the same type of arguments of
\fB-D\fP, but will *exclude* all the listed domains.
.TP
.B "All hosts"
When \fB-H\fP is specified without \fB-D\fP, all hosts are being spanned. It is
useful to set the recursion level to a small value in those cases.
Such option is rarely useful.
.TP
"\fIFTP\fP"
The rules for
.I FTP
are somewhat specific, since they have to be. To have
.I FTP
links followed from
.I HTML
documents, you must specify -f (follow_ftp). If you do specify it,
.I FTP
links will be able to span hosts even if span_hosts is not set.
Option relative_only (-L) has no effect on
.I FTP.
However, domain acceptance (-D) and suffix rules (-A/-R) still apply.

.SH "STARTUP FILE"
.B Wget
supports the use of initialization file
.IR .wgetrc .
First a system-wide init file will be looked for
(\fI/etc/wgetrc\fP by default) and loaded. Then the user's file
will be searched for in two places: In the environmental variable
\fIWGETRC\fP (which is presumed to hold the full pathname) and
.IR $HOME/.wgetrc .
Note that the settings in user's startup file may override the system
settings, which includes the quota settings (he he).
.PP
The syntax of each line of startup file is simple:
.sp
	\fIvariable\fP = \fIvalue\fP
.sp
Valid values are different for different variables. The complete set
of commands is listed below, the letter after equation\-sign denoting
the value the command takes. It is \fIon/off\fP for \fBon\fP or
\fBoff\fP (which can also be \fB1\fP or \fB0\fP), \fBstring\fP for any
string or \fBN\fP for positive integer.  For example, you may specify
"use_proxy = off" to disable use of proxy servers by default. You may
use \fBinf\fP for infinite value (the role of \fB0\fP on the command
line), where appropriate. The commands are case\-insensitive and
underscore\-insensitive, thus \fBDIr__Prefix\fP is the same as
\fBdirprefix\fP. Empty lines, lines consisting of spaces, or lines
beginning with '#' are skipped.

Most of the commands have their equivalent command\-line option,
except some more obscure or rarely used ones. A sample init file is
provided in the distribution, named \fIsample.wgetrc\fP.

.TP
.B "accept/reject = \fIstring\fP"
Same as \fB-A/-R\fP.
.TP
.B "add_hostdir = \fIon/off\fP"
Enable/disable host-prefixed hostnames. \fB-nH\fP disables it.
.TP
.B "always_rest = \fIon/off\fP"
Enable/disable continuation of the retrieval, the same as \fB-c\fP.
.TP
.B "base = \fIstring\fP"
Set base for relative URL-s, the same as \fB-B\fP.
.TP
.B "convert links = \fIon/off\fP"
Convert non-relative links locally. The same as \fB-k\fP.
.TP
.B "debug = \fIon/off\fP"
Debug mode, same as \fB-d\fP.
.TP
.B "dir_mode = \fIN\fP"
Set permission modes of created subdirectories (default is 755).
.TP
.B "dir_prefix = \fIstring\fP"
Top of directory tree, the same as \fB-P\fP.
.TP
.B "dirstruct = \fIon/off\fP"
Turning dirstruct on or off, the same as \fB-x\fP or \fB-nd\fP, respectively.
.TP
.B "domains = \fIstring\fP"
Same as \fB-D\fP.
.TP
.B "follow_ftp = \fIon/off\fP"
Follow
.I FTP
links from
.I HTML
documents, the same as \fB-f\fP.
.TP
.B "force_html = \fIon/off\fP"
If set to on, force the input filename to be regarded as an HTML
document, the same as \fB-F\fP.
.TP
.B "ftp_proxy = \fIstring\fP"
Use the string as \fIFTP\fP proxy, instead of the one specified in
environment.
.TP
.B "glob = \fIon/off\fP"
Turn globbing on/off, the same as \fB-g\fP.
.TP
.B "header = \fIstring\fP"
Define an additional header, like \fB--header\fP.
.TP
.B "http_passwd = \fIstring\fP"
Set \fIHTTP\fP password.
.TP
.B "http_proxy = \fIstring\fP"
Use the string as \fIHTTP\fP proxy, instead of the one specified in
environment.
.TP
.B "http_user = \fIstring\fP"
Set \fIHTTP\fP user.
.TP
.B "input = \fIstring\fP"
Read the URL-s from filename, like -i.
.TP
.B "kill_longer = \fIon/off\fP"
Consider data longer than specified in content-length header
as invalid (and retry getting it). The default behaviour is to save
as much data as there is, provided there is more than or equal
to the value in content-length.
.TP
.B "logfile = \fIstring\fP"
Set logfile, the same as \fB-o\fP.
.TP
.B "login = \fIstring\fP"
Your user name on the remote machine, for
.I FTP.
Defaults to "anonymous".
.TP
.B "mirror = \fIon/off\fP"
Turn mirroring on/off. The same as \fB-m\fP.
.TP
.B "noclobber = \fIon/off\fP"
Same as \fB-nc\fP.
.TP
.B "no_parent = \fIon/off\fP"
Same as \fB--no-parent\fP.
.TP
.B "no_proxy = \fIstring\fP"
Use the string as the comma\-separated list of domains to avoid in
proxy loading, instead of the one specified in environment.
.TP
.B "num_tries = \fIN\fP"
Set number of retries per URL, the same as \fB-t\fP.
.TP
.B "output_document = \fIstring\fP"
Set the output filename, the same as \fB-O\fP.
.TP
.B "passwd = \fIstring\fP"
Your password on the remote machine, for
.I FTP.
Defaults to
username@hostname.domainname.
.TP
.B "quiet = \fIon/off\fP"
Quiet mode, the same as \fB-q\fP.
.TP
.B "quota = \fIquota\fP"
Specify the download quota, which is useful to put in
\fI/etc/wgetrc\fP. When download quota is specified,
.B wget
will stop retrieving after the download sum has become greater than
quota. The quota can be specified in bytes (default), kbytes ('k'
appended) or mbytes ('m' appended). Thus "quota = 5m" will set the
quota to 5 mbytes. Note that the user's startup file overrides system
settings.
.TP
.B "reclevel = \fIN\fP"
Recursion level, the same as \fB-l\fP.
.TP
.B "recursive = \fIon/off\fP"
Recursive on/off, the same as \fB-r\fP.
.TP
.B "relative_only = \fIon/off\fP"
Follow only relative links (the same as -L). Refer to section
.I "FOLLOWING LINKS"
for a more detailed description.
.TP
.B "robots = \fIon/off\fP"
Use (or not) robots.txt file.
.TP
.B "server_response = \fIon/off\fP"
Choose whether or not to print the \fIHTTP\fP and \fIFTP\fP server
responses, the same as \fB-S\fP.
.TP
.B "simple_host_check = \fIon/off\fP"
Same as \fB-nh\fP.
.TP
.B "span_hosts = \fIon/off\fP"
Same as \fB-H\fP.
.TP
.B "timeout = \fIN\fP"
Set timeout value, the same as \fB-T\fP.
.TP
.B "timestamping = \fIon/off\fP"
Turn timestamping on/off. The same as \fB-N\fP.
.TP
.B "use_proxy = \fIon/off\fP"
Turn proxy support on/off. The same as \fB-Y\fP.
.TP
.B "verbose = \fIon/off\fP"
Turn verbose on/off, the same as \fB-v/-nv\fP.

.SH SIGNALS
.PP
.B Wget
will catch the \fISIGHUP\fP (hangup signal) and ignore it. If the
output was on stdout, it will be redirected to a file named
\fIwget-log\fP. This is also convenient when you wish to redirect
the output of \fBWget\fP interactively.

.nf
.ft B
$ wget http://www.ifi.uio.no/~larsi/gnus.tar.gz &
$ kill -HUP %%       # to redirect the output
.ft R
.fi

\fBWget\fP will not try to handle any signals other than
\fISIGHUP\fP. Thus you may interrupt \fBWget\fP using ^C or
\fISIGTERM\fP.

.SH EXAMPLES
.nf
Get URL http://fly.cc.fer.hr/:
.ft B
wget http://fly.cc.fer.hr/

.ft R
Force non\-verbose output:
.ft B
wget -nv http://fly.cc.fer.hr/

.ft R
Unlimit number of retries:
.ft B
wget -t0 http://www.yahoo.com/

.ft R
Create a mirror image of fly's web (with the same directory structure
the original has), up to six recursion levels, with only one try per
document, saving the verbose output to log file 'log':
'log':
.ft B
wget -r -l6 -t1 -o log http://fly.cc.fer.hr/

.ft R
Retrieve from yahoo host only (depth 50):
.ft B
wget -r -l50 http://www.yahoo.com/
.fi

.SH ENVIRONMENT
.BR http_proxy ,
.BR ftp_proxy ,
.BR no_proxy ,
.BR WGETRC ,
.B HOME

.SH FILES
.IR /etc/wgetrc ,
.I $HOME/.wgetrc

.SH UNRESTRICTIONS
.PP
.B Wget
is free; anyone may redistribute copies of 
.B Wget 
to anyone under the terms stated in the General Public License, a copy
of which accompanies each copy of
.BR Wget .

.SH "SEE ALSO"
.BR lynx (1),
.BR ftp (1)

.SH AUTHOR
.PP
Hrvoje Niksic <hniksic@srce.hr> is the author of Wget.  Thanks to the
beta testers and all the other people who helped with useful
suggestions.
.PP
This manpage is included only in the Debian version of wget. Wget author
is not responsible for any bugs it may contain.
